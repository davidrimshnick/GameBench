# AlphaZero training configuration
# Tuned for Jetson Orin Nano Super (8GB shared, CUDA 12.6)
network:
  num_res_blocks: 5
  num_filters: 64
  input_planes: 12
  board_size: 8

mcts:
  num_simulations: 25          # Low sims OK for self-play with NN guidance
  cpuct: 1.5
  dirichlet_alpha: 0.3
  dirichlet_epsilon: 0.25
  temperature_threshold: 30    # moves before temperature drops to near-zero

selfplay:
  num_games_per_iteration: 15  # Conservative for 8GB Jetson memory
  replay_buffer_size: 100000   # Conservative for memory
  num_workers: 1               # Sequential GPU inference (no CPU multiprocessing)

training:
  batch_size: 128              # Conservative for 8GB shared memory
  learning_rate: 0.01
  momentum: 0.9
  weight_decay: 0.0001
  steps_per_iteration: 200     # Reduced to match smaller data generation
  checkpoint_interval: 200
  eval_games: 6                 # Reduced for speed (saves ~20 min/iteration)
  eval_simulations: 25
  eval_threshold: 0.55         # win rate to accept new network
  max_iterations: 100

paths:
  checkpoint_dir: "checkpoints"
  log_dir: "logs"
  training_log: "training_log.jsonl"
